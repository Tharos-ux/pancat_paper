{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871338a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T14:24:29.934092Z",
     "iopub.status.busy": "2023-11-14T14:24:29.933556Z",
     "iopub.status.idle": "2023-11-14T14:24:29.939342Z",
     "shell.execute_reply": "2023-11-14T14:24:29.938346Z"
    },
    "papermill": {
     "duration": 0.016657,
     "end_time": "2023-11-14T14:24:29.942137",
     "exception": false,
     "start_time": "2023-11-14T14:24:29.925480",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "graph_folder:str = 'data'\n",
    "edition_file: str = 'temp/yeast_edit'\n",
    "matrix:str = 'temp/matrix.json'\n",
    "mash_matrix:str = 'temp/mash.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb6355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colorblind-friendly palette\n",
    "colors = {\n",
    "    'blue':    '#377eb8', \n",
    "    'orange':  '#ff7f00',\n",
    "    'green':   '#4daf4a',\n",
    "    'pink':    '#f781bf',\n",
    "    'brown':   '#a65628',\n",
    "    'purple':  '#984ea3',\n",
    "    'gray':    '#999999',\n",
    "    'red':     '#e41a1c',\n",
    "    'yellow':  '#dede00'\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0b27f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2023-11-14T14:24:29.948240",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from seaborn import heatmap, boxplot,stripplot, clustermap, scatterplot, regplot, color_palette\n",
    "from numpy import triu,array,add,zeros,column_stack, nan\n",
    "from matplotlib import pyplot as plt\n",
    "from os import listdir, path\n",
    "from collections import Counter\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib import patches as mpatches\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from subprocess import run, PIPE\n",
    "from scipy.spatial.distance import euclidean\n",
    "from statistics import mean,median\n",
    "from pandas import DataFrame,wide_to_long\n",
    "from pgGraphs import Graph\n",
    "from math import floor\n",
    "from os import system, remove, path\n",
    "from json import load, dump\n",
    "from tharospytools.matplotlib_tools import get_palette_from_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65fc793",
   "metadata": {},
   "source": [
    "Manipulating graph names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c4e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_graphs: list = sorted(listdir(graph_folder))\n",
    "all_graphs.insert(0, all_graphs.pop())\n",
    "print(all_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfa_graph:Graph = Graph(\n",
    "    gfa_file=f'data/{all_graphs[0]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c6ee66",
   "metadata": {},
   "source": [
    "Computing pairwise mash distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_paths:list[str] = sorted(list(gfa_graph.paths.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists(mash_matrix):\n",
    "    mash: list[list[int]] = load(open(mash_matrix,'r',encoding='utf-8'))\n",
    "else:\n",
    "    mash:list[list[float]] = [\n",
    "            [\n",
    "            0 for _ in range(len(graph_paths))\n",
    "        ] for _ in range(len(graph_paths))\n",
    "    ]\n",
    "\n",
    "    for i,path_name_A in enumerate(graph_paths):\n",
    "        for j,path_name_B in enumerate(graph_paths):\n",
    "            mash[i][j]=float(run(['mash', 'dist',f'temp/{path_name_A}.fa',f'temp/{path_name_B}.fa'], stdout=PIPE).stdout.decode('utf-8').split()[2])\n",
    "    dump(mash,open(mash_matrix,'w',encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbf1255",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in mash:\n",
    "    print(\"\\t\".join([str(elt) for elt in row]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045daac6",
   "metadata": {},
   "source": [
    "Computing mean and median of mash distance to every other for each sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2270dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mash:dict = {\n",
    "    path_name:mean(mash[i]) for i,path_name in enumerate(graph_paths)\n",
    "}\n",
    "\n",
    "median_mash:dict = {\n",
    "    path_name:median(mash[i]) for i,path_name in enumerate(graph_paths)\n",
    "}\n",
    "\n",
    "sum_mash:dict = {\n",
    "    path_name:sum(mash[i]) for i,path_name in enumerate(graph_paths)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a98b2a",
   "metadata": {},
   "source": [
    "Computing distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we compute edition to be sure to have a list of breakpoints\n",
    "distance_martix:list[list[int]] = [[0 for _ in all_graphs] for _ in all_graphs]\n",
    "\n",
    "if path.exists(matrix):\n",
    "    distance_martix: list[list[int]] = load(open(matrix,'r',encoding='utf-8'))\n",
    "else:\n",
    "    for i,graph_A in enumerate(all_graphs):\n",
    "        for j,graph_B in enumerate(all_graphs):\n",
    "            if i < j:\n",
    "                # Compute edition\n",
    "                system(f'pancat edit data/{graph_A} data/{graph_B} -o {edition_file}_{i}_{j}.json')\n",
    "                # Load edit file in memory\n",
    "                editions:dict[str,list] = load(open(f\"{edition_file}_{i}_{j}.json\",'r',encoding='utf-8'))\n",
    "                # Count editions\n",
    "                edit_count:int = sum([sum([len(edit_list) for edit_list in edition_classes.values()]) for edition_classes in editions.values()])\n",
    "                # add count to the two positions\n",
    "                distance_martix[i][j] = edit_count\n",
    "                distance_martix[j][i] = edit_count\n",
    "                # delete temp file\n",
    "                #remove(edition_file)\n",
    "                \n",
    "    dump(distance_martix,open(matrix,'w',encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b34d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in distance_martix:\n",
    "    print(\"\\t\".join([str(elt) for elt in row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c5308",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels:list[str] = ['PGGB' if 'pggb' in label else label.split('_')[3] for label in all_graphs]\n",
    "green_pal = color_palette(\"dark:#5A9\", as_cmap=True)\n",
    "colors = ['white'] + get_palette_from_list([sum_mash[x] for x in graph_paths],cmap_name='Greens')\n",
    "fig = clustermap(distance_martix, linewidth=0.5, annot=False, xticklabels=['PGGB']+[round(sum_mash[x],3) for x in graph_paths], yticklabels=labels,cmap=green_pal,col_colors=colors,row_colors=colors)\n",
    "fig.tick_params(length=0)\n",
    "fig.ax_heatmap.set_yticklabels(fig.ax_heatmap.get_yticklabels(), rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1754c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd4fa9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories: str = ['String', 'SuperString', 'SubString', 'SubSuffix', 'SuperPrefix',\n",
    "                    'SubPrefix', 'SuperSuffix', 'OverlapSuffixPrefix', 'OverlapPrefixSuffix','Splits','Merges']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig, axs = plt.subplots(ncols=len(categories))\n",
    "size_square:int = len(all_graphs)\n",
    "select:list|None = None #[\"seq3\"]\n",
    "\n",
    "table: dict[str, list[list[int]]] = {category: [\n",
    "    [0 for _ in range(len(all_graphs))] for _ in range(len(all_graphs))] for category in categories}\n",
    "\n",
    "dipaths:list = list()\n",
    "deltas:list = list()\n",
    "for i, graph_1 in enumerate(all_graphs):\n",
    "    print(f\"Starting comparisons on graph {graph_1} ({i+1}/{size_square})\")\n",
    "    for j, graph_2 in enumerate(all_graphs):\n",
    "        results, all_dipaths,deltas_counter = perform_edition(\n",
    "            files=[path.join(graph_folder, graph_1), path.join(graph_folder, graph_2)],\n",
    "            gfa_versions=['GFA1.1', 'GFA1.1'],\n",
    "            selection=select,\n",
    "            distance_mode='graph_level'\n",
    "            )\n",
    "        dipaths.append(all_dipaths)\n",
    "        deltas.append(deltas_counter)\n",
    "        for category in categories:\n",
    "            table[category][i][j] = results[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e017b99",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph_names:list = [x.split('.')[0] for x in all_graphs]\n",
    "\n",
    "for i, (category, datas) in enumerate(table.items()):\n",
    "    # axs[i].set_title(category)\n",
    "    fig = plt.figure(figsize=(size_square+2, size_square+2))\n",
    "    plt.title(category)\n",
    "    ax = heatmap(datas, linewidth=0.5, annot=True,\n",
    "                        cbar=False, xticklabels=graph_names, yticklabels=graph_names)  # ax=axs[i]\n",
    "    \n",
    "    wanted_index = graph_names.index(final_name)\n",
    "    x, y, w, h = 0, wanted_index, size_square, 1\n",
    "    for _ in range(2):\n",
    "        ax.add_patch(Rectangle((x, y), w, h, fill=False, edgecolor='crimson', lw=4, clip_on=False))\n",
    "        x, y = y, x # exchange the roles of x and y\n",
    "        w, h = h, w # exchange the roles of w and h\n",
    "    ax.tick_params(length=0)\n",
    "    plt.savefig(path.join(output_folder,f\"graph_{category}.png\"), bbox_inches='tight')\n",
    "    save_dynamic_fig(fig,path.join(output_folder,f\"graph_{category}.pkl\"))\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d8414c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "\n",
    "plt.rcParams['grid.color'] = (0.5, 0.5, 0.5, 0.3)\n",
    "\n",
    "for category,data in table.items():\n",
    "    # setting distance_threshold=0 ensures we compute the full tree.\n",
    "    model = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
    "    model = model.fit(data)\n",
    "    plt.title(f\"Hierarchical Clustering Dendrogram on {category}\")\n",
    "    plt.tick_params(length=0)\n",
    "    # plot the top three levels of the dendrogram\n",
    "    plot_dendrogram(model, truncate_mode=\"level\", p=3, labels=graph_names,leaf_rotation=90.,leaf_font_size=8.)\n",
    "    plt.box(False)\n",
    "    plt.ylabel('Cluster distance')\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.grid(axis = 'y',linestyle='--')\n",
    "    plt.show()\n",
    "    save_dynamic_fig(fig,path.join(output_folder,f\"graph_editions_{category}.pkl\"))\n",
    "    plt.savefig(path.join(output_folder,f\"graph_editions_{category}.png\"), bbox_inches='tight')\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4b854",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Computing euclidian distance between edition patterns\n",
    "\n",
    "matrix = add(array(table[\"Merges\"]),array(table[\"Splits\"]))\n",
    "\n",
    "mx1 = [[elt for x,elt in enumerate(row) if x!=y] for y,row in enumerate(matrix)]\n",
    "mx2 = [[elt if x!=y and 'pggb' not in graph_names[x] else None for x,elt in enumerate(row)] for y,row in enumerate(matrix)]\n",
    "mx3 = [[elt if x!=y and 'pggb' in graph_names[x] else None for x,elt in enumerate(row)] for y,row in enumerate(matrix)]\n",
    "\n",
    "# For each line in the matrix, compute the distance with every other, and keep the one with the lowest mean distance\n",
    "lowest_distance:list = [mean([euclidean(reference,line) for i,line in enumerate(matrix) if i !=j]) for j,reference in enumerate(matrix)]\n",
    "idx:int = lowest_distance.index(min(lowest_distance))\n",
    "\n",
    "df1 = DataFrame(mx1).T\n",
    "df1 = df1.rename(columns={k: f'Data{k+1}' for k in range(len(mx1))}).reset_index()\n",
    "df1 = wide_to_long(df1, stubnames = ['Data'], i = 'index', j = 'ID').reset_index()[['ID', 'Data']]\n",
    "\n",
    "df2 = DataFrame(mx2).T\n",
    "df2 = df2.rename(columns={k: f'Data{k+1}' for k in range(len(mx2))}).reset_index()\n",
    "df2 = wide_to_long(df2, stubnames = ['Data'], i = 'index', j = 'ID').reset_index()[['ID', 'Data']]\n",
    "\n",
    "daf = DataFrame(mx3).T\n",
    "daf = daf.rename(columns={k: f'Data{k+1}' for k in range(len(mx3))}).reset_index()\n",
    "daf = wide_to_long(daf, stubnames = ['Data'], i = 'index', j = 'ID').reset_index()[['ID', 'Data']]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(len(graph_names)+2,8)\n",
    "pal = {str(i+1):'red' if 'pggb' in graph_names[i] else 'orange' for i in range(len(graph_names))}\n",
    "boxplot(x='ID', y = 'Data', data = df1, boxprops={'alpha': 0.4},palette=pal)\n",
    "stripplot(data=df2, x=\"ID\", y=\"Data\", dodge=True, ax=ax, color=colors['orange'])\n",
    "stripplot(data=daf, x=\"ID\", y=\"Data\", dodge=True, ax=ax, color=colors['red'])\n",
    "plt.xlabel(\"Graphs\")\n",
    "ax.set_xticklabels(graph_names)\n",
    "for lab in ax.get_xticklabels():\n",
    "   if lab.get_text() == graph_names[idx]:\n",
    "      lab.set_fontweight('bold')\n",
    "red_patch = mpatches.Patch(color=colors['red'], label='PGGB')\n",
    "orange_patch = mpatches.Patch(color=colors['orange'], label='MGC')\n",
    "plt.legend(handles=[red_patch, orange_patch])\n",
    "plt.ylabel(\"Edit distance\")\n",
    "save_dynamic_fig(fig,path.join(output_folder,f\"graph_euclidian.pkl\"))\n",
    "plt.savefig(path.join(output_folder,f\"graph_euclidian.png\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320df91f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Computing editions\n",
    "mask = triu(matrix)\n",
    "\n",
    "plt.figure(figsize=(size_square+2, size_square+2))\n",
    "plt.title(\"Editions\")\n",
    "ax = heatmap(matrix, linewidth=0.5, annot=True,\n",
    "                    cbar=False, mask=mask, xticklabels=graph_names, yticklabels=graph_names)  # ax=axs[i]\n",
    "wanted_index = graph_names.index(final_name)\n",
    "x, y, w, h = 0, wanted_index, size_square, 1\n",
    "x, y = y, x # exchange the roles of x and y\n",
    "w, h = h, w # exchange the roles of w and h\n",
    "ax.add_patch(Rectangle((x, y), w, h, fill=False, edgecolor='crimson', lw=4, clip_on=False))\n",
    "\n",
    "ax.tick_params(length=0)\n",
    "plt.savefig(path.join(output_folder,f\"graph_editions_triangle.png\"), bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c86bde",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Clustermap des éditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ad35c5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = clustermap(matrix, linewidth=0.5, annot=True, xticklabels=graph_names, yticklabels=graph_names,metric=\"correlation\")\n",
    "fig.tick_params(length=0)\n",
    "fig.savefig(path.join(output_folder,f\"graph_clustering.png\"), bbox_inches='tight')\n",
    "fig.ax_heatmap.set_yticklabels(fig.ax_heatmap.get_yticklabels(), rotation=0)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc24d973",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Displaying events sizes        \n",
    "from numpy import cumsum\n",
    "\n",
    "for i,dc in enumerate(deltas):\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    plt.title(\"Lengths of $\\Delta_{events}$\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xscale(\"log\")\n",
    "    for category,compteur in dc.items():\n",
    "        try:\n",
    "            x=list(range(max(list(compteur.keys()))))\n",
    "            y=cumsum([compteur[i] if i in compteur else 0 for i in range(max(list(compteur.keys())))])\n",
    "            plt.plot(x,y, label = category, alpha=0.6)\n",
    "        except:\n",
    "            print(f\"{category} -> {compteur}\")\n",
    "\n",
    "    plt.ylabel(\"Cumulative sum of $\\Delta_{events}$\")\n",
    "    plt.legend(loc = 'upper left')\n",
    "    plt.savefig(path.join(output_folder,f\"deltas_lengths_{i}.png\"), bbox_inches='tight')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee805ba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Analyse de la corrélation entre la moyenne des mash distance à la référence et la proximité du graphe *minigraph-cactus* avec la plus basse moyenne au graphe *PGGB*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b44999c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "mash:dict = {}\n",
    "\n",
    "for file in listdir(pipeline_folder):\n",
    "    with open(path.join(pipeline_folder,file),'r',encoding='utf-8') as pipl:\n",
    "        all_lines:list = pipl.readlines()\n",
    "        reference,alternates = all_lines[0].split()[1],[line.split()[1] for line in all_lines[1:]]\n",
    "        mash[file.split('.')[0]]=[float(run(['mash', 'dist',reference,alt], stdout=PIPE).stdout.decode('utf-8').split()[2]) for alt in alternates]\n",
    "\n",
    "mean_mash:dict = {k:mean(v) for k,v in mash.items()}\n",
    "median_mash:dict = {k:median(v) for k,v in mash.items()}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a79333",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dtf = DataFrame([mean_mash]).T\n",
    "dtf = dtf.rename(columns={0:'mash_dist'})\n",
    "dtf[\"pggb_dist\"] = [matrix[graph_names.index(x)][graph_names.index(final_name)] for x,_ in dtf.iterrows()]\n",
    "\n",
    "dtf2 = DataFrame([median_mash]).T\n",
    "dtf2 = dtf2.rename(columns={0:'mash_dist'})\n",
    "dtf2[\"pggb_dist\"] = [matrix[graph_names.index(x)][graph_names.index(final_name)] for x,_ in dtf2.iterrows()]\n",
    "\n",
    "#m, b = np.polyfit(dtf['mash_dist'], dtf['pggb_dist'], 1)\n",
    "#plt.plot(dtf['mash_dist'], m*dtf['mash_dist']+b, color='red')\n",
    "ax1 = fig.add_subplot()\n",
    "regplot(x=dtf['mash_dist'], y=dtf['pggb_dist'],scatter_kws={'alpha':0.3},line_kws=dict(alpha=0.3, color=colors['orange'], linewidth=3), ax=ax1)\n",
    "scatterplot(data=dtf, x=\"mash_dist\", y=\"pggb_dist\", color=colors['red'], ax=ax1)\n",
    "#plt.xlabel(\"Mean mash distance\")\n",
    "ax1.set_ylabel(\"Distance to PGGB graph\")\n",
    "ax2 = ax1.twinx()\n",
    "regplot(x=dtf2['mash_dist'], y=dtf2['pggb_dist'],scatter_kws={'alpha':0.3},line_kws=dict(alpha=0.3, color=colors['purple'], linewidth=3), ax=ax2)\n",
    "scatterplot(data=dtf2, x=\"mash_dist\", y=\"pggb_dist\", color=colors['blue'], ax=ax2)\n",
    "ax2.set_ylabel(\"Distance to PGGB graph\")\n",
    "plt.savefig(path.join(output_folder,f\"mash_correlation.png\"), bbox_inches='tight')\n",
    "plt.clf()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e69aa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i,seq_dipaths in enumerate(dipaths):\n",
    "    # Plotting repartition of edits along the reference\n",
    "    categories_left: str = ['Overlaps', 'Equivalences', 'Inclusions']\n",
    "    categories_right: str = [('Splits',colors['red']),('Merges',colors['green'])]\n",
    "\n",
    "    sampling:int = 100\n",
    "    lengths:int = [int(p.datas['stop_offset'])-int(p.datas['start_offset']) for p in Graph(gfa_file=path.join(graph_folder, all_graphs[1]),gfa_type='GFA1.1',with_sequence=True).get_path_list()]\n",
    "    counts = [{x:0 for x in categories_left+['Splits']+['Merges']} for _ in range(sampling)]\n",
    "    # here, iterating on graphs\n",
    "    if i//len(graph_names) != i%len(graph_names):\n",
    "        # we don't compute if we compare the same graphs\n",
    "        for j,dipath in enumerate(seq_dipaths):\n",
    "            # we're iterating on the dipaths of a single comparison at this level\n",
    "            curr_length = lengths[j]\n",
    "            # compute sectors here\n",
    "            for edition_list in dipath.edition.values():\n",
    "                curr_index = floor((edition_list[0].offsets_ref[0]/curr_length)*sampling)\n",
    "                if curr_index > sampling-1:\n",
    "                    print(f\"WARNING! Index value = {curr_index}\")\n",
    "                    curr_index = sampling-1\n",
    "                counts[curr_index]['Merges'] += max(0, len(edition_list)-1)\n",
    "                for edit_element in edition_list:\n",
    "                    if type(edit_element).__name__ in ['OverlapPrefixSuffix','OverlapSuffixPrefix']:\n",
    "                        counts[curr_index]['Overlaps'] += 1\n",
    "                        if type(edit_element).__name__ == 'OverlapPrefixSuffix':\n",
    "                            counts[curr_index]['Splits'] +=1\n",
    "                    elif type(edit_element).__name__ in ['SubSuffix','SubPrefix','SuperString','SubString','SuperPrefix','SuperSuffix']:\n",
    "                        counts[curr_index]['Inclusions'] += 1\n",
    "                        if type(edit_element).__name__ in ['SuperPrefix','SuperString']:\n",
    "                            counts[curr_index]['Splits'] +=1\n",
    "                    elif type(edit_element).__name__ == 'String':\n",
    "                        counts[curr_index]['Equivalences'] += 1\n",
    "            \n",
    "        fig = plt.figure(figsize=(20,5))\n",
    "        fig.suptitle(f\"Distribution of events for {graph_names[i//len(graph_names)]} against {graph_names[i%len(graph_names)]}\")\n",
    "\n",
    "        x = list(range(sampling))\n",
    "\n",
    "        ax1 = fig.add_subplot()\n",
    "        ax1.tick_params(axis='x',which='both',bottom=False,top=False,labelbottom=False)\n",
    "        \n",
    "        for category in categories_left:\n",
    "            ax1.plot(x,[counts[sector][category] for sector in x], label = category, alpha=0.6)\n",
    "        \n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.tick_params(axis='x',which='both',bottom=False,top=False,labelbottom=False)\n",
    "\n",
    "        for category,color in categories_right:\n",
    "            ax2.plot(x,[counts[sector][category] for sector in x], color=color, label = category,linestyle='dashed', alpha=0.8)\n",
    "\n",
    "        ax1.set_ylabel(\"Events\")\n",
    "        ax2.set_ylabel(\"Editions\")\n",
    "        ax1.legend(loc = 'upper left')\n",
    "        ax2.legend(loc = 'upper right')\n",
    "        ax1.set_xlim(0,99)\n",
    "        ax2.set_xlim(0,99)\n",
    "        \n",
    "        save_dynamic_fig(ax1,path.join(output_folder,f\"graph_{graph_names[i//len(graph_names)]}_{graph_names[i%len(graph_names)]}_ax1.pkl\"))\n",
    "        save_dynamic_fig(ax2,path.join(output_folder,f\"graph_{graph_names[i//len(graph_names)]}_{graph_names[i%len(graph_names)]}_ax2.pkl\"))\n",
    "        save_dynamic_fig(fig,path.join(output_folder,f\"graph_{graph_names[i//len(graph_names)]}_{graph_names[i%len(graph_names)]}_fig.pkl\"))\n",
    "        \n",
    "        plt.savefig(path.join(output_folder,f\"graph_{graph_names[i//len(graph_names)]}_{graph_names[i%len(graph_names)]}.png\"), bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.clf()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "notebook.ipynb",
   "output_path": "output.ipynb",
   "parameters": {
    "final_name": "pggb_final",
    "graph_folder": "/scratch/sdubois/pggb_vs_cactus/graphs_pggb_vs_all",
    "output_folder": "/scratch/sdubois/YEAST_6_11_23_graphs",
    "pipeline_folder": "/scratch/sdubois/levures_rotate/pipeline"
   },
   "start_time": "2023-11-14T14:24:26.457982",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
